# backend/services/ai/ai_service.py
"""
–ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å AI —Å–µ—Ä–≤–∏—Å–∞
–ö–æ–æ—Ä–¥–∏–Ω–∏—Ä—É–µ—Ç —Ä–∞–±–æ—Ç—É –≤—Å–µ—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤ –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –µ–¥–∏–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
"""

import os
import logging
from typing import Dict, Any, List, Optional, AsyncIterator
from openai import AsyncOpenAI

from .prompts import get_system_prompt, TOOL_METADATA
from .image_processor import ImageProcessor
from .audio_processor import AudioProcessor
from .document_processor import DocumentProcessor
from .response_handler import ResponseHandler

logger = logging.getLogger(__name__)


class AIService:
    """–ì–ª–∞–≤–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å AI —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å—é"""

    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AI —Å–µ—Ä–≤–∏—Å–∞"""
        # –ü–æ–ª—É—á–∞–µ–º API –∫–ª—é—á
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∏–µ–Ω—Ç OpenAI
        self.client = AsyncOpenAI(api_key=api_key)
        self.model = os.getenv("OPENAI_MODEL", "gpt-4o")

        logger.info(f"AIService initialized with model: {self.model}")

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä—ã
        self.image_processor = ImageProcessor(max_image_size=2048)
        self.audio_processor = AudioProcessor(openai_client=self.client)
        self.document_processor = DocumentProcessor(max_text_length=5000)
        self.response_handler = ResponseHandler(
            openai_client=self.client,
            model=self.model,
            default_max_tokens=2000
        )

        logger.info("All processors initialized successfully")

    # ==================== –û–°–ù–û–í–ù–´–ï –ú–ï–¢–û–î–´ –î–õ–Ø –†–ê–ë–û–¢–´ –° GPT ====================

    async def get_response_stream(
            self,
            message: str,
            context: Dict[str, Any] = None,
            chat_history: List[Dict[str, Any]] = None,
            files_context: str = '',
    ) -> AsyncIterator[str]:
        """
        –ü–æ–ª—É—á–∏—Ç—å –ø–æ—Ç–æ–∫–æ–≤—ã–π –æ—Ç–≤–µ—Ç –æ—Ç GPT

        Args:
            message: –°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            context: –ö–æ–Ω—Ç–µ–∫—Å—Ç (tool_type –∏ —Ç.–¥.)
            chat_history: –ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞
            files_context: –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–æ–≤

        Yields:
            –ß–∞—Å—Ç–∏ –æ—Ç–≤–µ—Ç–∞ (chunks)
        """
        logger.info(f"Getting streaming response for message: '{message[:50]}...'")

        async for chunk in self.response_handler.get_response_stream(
                message=message,
                context=context or {},
                chat_history=chat_history or [],
                files_context=files_context
        ):
            yield chunk

    async def get_response(
            self,
            message: str,
            context: Dict[str, Any] = None,
            chat_history: List[Dict[str, Any]] = None,
            files_context: str = ''
    ) -> str:
        """
        –ü–æ–ª—É—á–∏—Ç—å –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç GPT (–Ω–µ –ø–æ—Ç–æ–∫–æ–≤—ã–π)

        Args:
            message: –°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            context: –ö–æ–Ω—Ç–µ–∫—Å—Ç
            chat_history: –ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞
            files_context: –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–æ–≤

        Returns:
            –ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç GPT
        """
        logger.info(f"Getting single response for message: '{message[:50]}...'")

        return await self.response_handler.get_single_response(
            message=message,
            context=context or {},
            chat_history=chat_history or [],
            files_context=files_context
        )

    # ==================== –ú–ï–¢–û–î–´ –î–õ–Ø –†–ê–ë–û–¢–´ –° –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø–ú–ò ====================

    async def analyze_image(
            self,
            image_path: str,
            prompt: str = ""
    ) -> str:
        """
        –ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ GPT-4 Vision

        Args:
            image_path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é
            prompt: –ü—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
        """
        try:
            logger.info(f"Analyzing image: {image_path}")

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É Vision
            if not self.image_processor.is_vision_model_supported(self.model):
                return (
                    f"üî∏ –ú–æ–¥–µ–ª—å {self.model} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. "
                    f"–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ gpt-4o –∏–ª–∏ gpt-4o-mini."
                )

            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è Vision API
            image_data = self.image_processor.prepare_image_for_vision_api(
                image_path,
                detail="auto"
            )

            if not image_data:
                return "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ."

            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç
            analysis_prompt = (
                "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –¥–µ—Ç–∞–ª—å–Ω–æ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ.\n\n"

                "–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –£–ö–ê–ñ–ò:\n"
                "1. **–¢–ï–ö–°–¢** (–µ—Å–ª–∏ –µ—Å—Ç—å):\n"
                "   - –í–µ—Å—å –≤–∏–¥–∏–º—ã–π —Ç–µ–∫—Å—Ç –¥–æ—Å–ª–æ–≤–Ω–æ, –ø–æ—Å—Ç—Ä–æ—á–Ω–æ\n"
                "   - –ó–∞–≥–æ–ª–æ–≤–∫–∏, –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∏, –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç\n"
                "   - –§–æ—Ä–º—É–ª—ã, —É—Ä–∞–≤–Ω–µ–Ω–∏—è, –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è\n"
                "   - –¢–∞–±–ª–∏—Ü—ã –∏ –∏—Ö —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ\n"
                "   - –ü–æ–¥–ø–∏—Å–∏ –∫ –¥–∏–∞–≥—Ä–∞–º–º–∞–º, –≥—Ä–∞—Ñ–∏–∫–∞–º\n\n"

                "2. **–í–ò–ó–£–ê–õ–¨–ù–´–ô –ö–û–ù–¢–ï–ù–¢**:\n"
                "   - –û—Å–Ω–æ–≤–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã –∏ –∏—Ö —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ\n"
                "   - –ì—Ä–∞—Ñ–∏–∫–∏, –¥–∏–∞–≥—Ä–∞–º–º—ã, —Å—Ö–µ–º—ã (—Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –¥–∞–Ω–Ω—ã—Ö)\n"
                "   - –§–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏, –∏–ª–ª—é—Å—Ç—Ä–∞—Ü–∏–∏ (—á—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ)\n"
                "   - –¶–≤–µ—Ç–∞, —Å—Ç–∏–ª—å –æ—Ñ–æ—Ä–º–ª–µ–Ω–∏—è\n\n"

                "3. **–°–¢–†–£–ö–¢–£–†–ê –ò –ö–û–ù–¢–ï–ö–°–¢**:\n"
                "   - –¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞ (—Å–∫—Ä–∏–Ω—à–æ—Ç, —Ñ–æ—Ç–æ –¥–æ—Å–∫–∏, —É—á–µ–±–Ω–∏–∫, –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è, –∑–∞–¥–∞—á–∞ –∏ —Ç.–¥.)\n"
                "   - –ü—Ä–µ–¥–º–µ—Ç–Ω–∞—è –æ–±–ª–∞—Å—Ç—å (–º–∞—Ç–µ–º–∞—Ç–∏–∫–∞, —Ñ–∏–∑–∏–∫–∞, –∏—Å—Ç–æ—Ä–∏—è –∏ —Ç.–¥.)\n"
                "   - –í–∞–∂–Ω—ã–µ –¥–µ—Ç–∞–ª–∏ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è —Ç–µ–º—ã\n\n"

                "4. **–û–ë–†–ê–ó–û–í–ê–¢–ï–õ–¨–ù–ê–Ø –¶–ï–ù–ù–û–°–¢–¨**:\n"
                "   - –ï—Å–ª–∏ —ç—Ç–æ –∑–∞–¥–∞—á–∞ - –æ–ø–∏—à–∏ —É—Å–ª–æ–≤–∏–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é\n"
                "   - –ï—Å–ª–∏ —ç—Ç–æ –∫–æ–Ω—Å–ø–µ–∫—Ç - –≤—ã–¥–µ–ª–∏ –∫–ª—é—á–µ–≤—ã–µ –ø–æ–Ω—è—Ç–∏—è\n"
                "   - –ï—Å–ª–∏ —ç—Ç–æ —Ç–∞–±–ª–∏—Ü–∞ - —Å–æ—Ö—Ä–∞–Ω–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö\n\n"

                "–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê:\n"
                "–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Ç–∞–∫, —á—Ç–æ–±—ã –µ—ë –º–æ–∂–Ω–æ –±—ã–ª–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è:\n"
                "- –ü–æ–∏—Å–∫–∞ –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É\n"
                "- –û—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã –æ–± —ç—Ç–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏\n"
                "- –°–æ–∑–¥–∞–Ω–∏—è –∫–æ–Ω—Å–ø–µ–∫—Ç–æ–≤ –∏ –∑–∞–º–µ—Ç–æ–∫\n"
                "- –†–µ—à–µ–Ω–∏—è –∑–∞–¥–∞—á –∏–∑ —ç—Ç–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n\n"

                "–ë—É–¥—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–Ω—ã–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–π –í–°–Æ –≤–∞–∂–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é!"
            )

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ Vision API
            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[{
                    "role": "user",
                    "content": [
                        {"type": "text", "text": analysis_prompt},
                        image_data
                    ]
                }],
                max_tokens=1000
            )

            result = response.choices[0].message.content

            logger.info(f"Image analysis completed: {len(result)} characters")

            return result

        except Exception as e:
            logger.error(f"Image analysis error: {e}", exc_info=True)
            return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}"

    def encode_image_to_base64(self, image_path: str) -> Optional[str]:
        """
        –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ base64

        Args:
            image_path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é

        Returns:
            Base64 —Å—Ç—Ä–æ–∫–∞ –∏–ª–∏ None
        """
        return self.image_processor.encode_image_to_base64(image_path)

    def get_image_info(self, image_path: str) -> dict:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏

        Args:
            image_path: –ü—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        """
        return self.image_processor.get_image_info(image_path)

    # ==================== –ú–ï–¢–û–î–´ –î–õ–Ø –†–ê–ë–û–¢–´ –° –ê–£–î–ò–û ====================

    async def transcribe_audio(
            self,
            file_path: str,
            language: Optional[str] = None
    ) -> str:
        """
        –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ Whisper API

        Args:
            file_path: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É
            language: –Ø–∑—ã–∫ –∞—É–¥–∏–æ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)

        Returns:
            –¢–µ–∫—Å—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏
        """
        logger.info(f"Transcribing audio: {file_path}")

        return await self.audio_processor.extract_text_from_audio(
            file_path,
            language=language
        )

    async def convert_audio_to_mp3(self, input_path: str) -> str:
        """
        –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∞—É–¥–∏–æ –≤ MP3

        Args:
            input_path: –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É —Ñ–∞–π–ª—É

        Returns:
            –ü—É—Ç—å –∫ MP3 —Ñ–∞–π–ª—É
        """
        return await self.audio_processor.convert_audio_to_mp3(input_path)

    def get_audio_info(self, file_path: str) -> dict:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∞—É–¥–∏–æ —Ñ–∞–π–ª–µ

        Args:
            file_path: –ü—É—Ç—å –∫ –∞—É–¥–∏–æ —Ñ–∞–π–ª—É

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        """
        return self.audio_processor.get_audio_info(file_path)

    # ==================== –ú–ï–¢–û–î–´ –î–õ–Ø –†–ê–ë–û–¢–´ –° –î–û–ö–£–ú–ï–ù–¢–ê–ú–ò ====================

    async def analyze_document(
            self,
            file_path: str,
            file_type: str,
            prompt: str = ""
    ) -> str:
        """
        –ê–Ω–∞–ª–∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º —Ç–µ–∫—Å—Ç–∞

        Args:
            file_path: –ü—É—Ç—å –∫ –¥–æ–∫—É–º–µ–Ω—Ç—É
            file_type: MIME —Ç–∏–ø —Ñ–∞–π–ª–∞
            prompt: –ü—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
        """
        try:
            logger.info(f"Analyzing document: {file_path}, type: {file_type}")

            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞
            extracted_text = await self.document_processor.extract_text_from_file(
                file_path,
                file_type
            )

            if not extracted_text or extracted_text.startswith("–û—à–∏–±–∫–∞"):
                return extracted_text

            # –ï—Å–ª–∏ –Ω–µ—Ç –ø—Ä–æ–º–ø—Ç–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—Ä–æ—Å—Ç–æ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
            if not prompt:
                return extracted_text

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å –ø–æ–º–æ—â—å—é GPT
            file_name = os.path.basename(file_path)
            analysis_prompt = (
                f"{prompt}\n\n"
                f"–°–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ '{file_name}':\n{extracted_text}"
            )

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[{
                    "role": "user",
                    "content": analysis_prompt
                }],
                max_tokens=1000
            )

            result = response.choices[0].message.content

            logger.info(f"Document analysis completed: {len(result)} characters")

            return result

        except Exception as e:
            logger.error(f"Document analysis error: {e}", exc_info=True)
            return f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞: {str(e)}"

    async def extract_text_from_file(
            self,
            file_path: str,
            file_type: str
    ) -> str:
        """
        –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞

        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
            file_type: MIME —Ç–∏–ø —Ñ–∞–π–ª–∞

        Returns:
            –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        logger.info(f"Extracting text from file: {file_path}, type: {file_type}")

        # –î–ª—è –∞—É–¥–∏–æ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
        if file_type.startswith("audio/") or "audio" in file_type:
            return await self.audio_processor.extract_text_from_audio(file_path)

        # –î–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º document processor
        return await self.document_processor.extract_text_from_file(
            file_path,
            file_type
        )

    def get_document_info(self, file_path: str) -> dict:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥–æ–∫—É–º–µ–Ω—Ç–µ

        Args:
            file_path: –ü—É—Ç—å –∫ –¥–æ–∫—É–º–µ–Ω—Ç—É

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π
        """
        return self.document_processor.get_document_info(file_path)

    # ==================== –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –ú–ï–¢–û–î–´ ====================

    async def health_check(self) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ OpenAI API

        Returns:
            True –µ—Å–ª–∏ API –¥–æ—Å—Ç—É–ø–µ–Ω
        """
        try:
            logger.info("Performing health check...")

            response = await self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": "Test"}],
                max_tokens=5
            )

            logger.info("Health check passed")
            return True

        except Exception as e:
            logger.error(f"Health check failed: {e}")
            return False

    def get_file_suggestions(self, file_type: str, file_name: str) -> str:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –ø–æ —Ä–∞–±–æ—Ç–µ —Å —Ñ–∞–π–ª–æ–º

        Args:
            file_type: MIME —Ç–∏–ø —Ñ–∞–π–ª–∞
            file_name: –ò–º—è —Ñ–∞–π–ª–∞

        Returns:
            –¢–µ–∫—Å—Ç —Å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏
        """
        suggestions = {
            'image': [
                "–û–ø–∏—à–∏—Ç–µ, —á—Ç–æ –≤—ã –≤–∏–¥–∏—Ç–µ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏",
                "–ù—É–∂–Ω–∞ –ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–ª–∏ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è?",
                "–•–æ—Ç–∏—Ç–µ —Å–æ–∑–¥–∞—Ç—å –ø–æ—Ö–æ–∂–µ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –¥—Ä—É–≥–æ–º —Å—Ç–∏–ª–µ?",
                "–ù—É–∂–µ–Ω –∞–Ω–∞–ª–∏–∑ –∫–æ–º–ø–æ–∑–∏—Ü–∏–∏, —Ü–≤–µ—Ç–æ–≤ –∏–ª–∏ —Å—Ç–∏–ª—è?"
            ],
            'audio': [
                "–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —Ä–µ—á—å –≤ —Ç–µ–∫—Å—Ç",
                "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–Ω –∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥–æ–ª–æ—Å–∞",
                "–ò–∑–≤–ª–µ—á—å –∫–ª—é—á–µ–≤—ã–µ —Ñ—Ä–∞–∑—ã –∏–∑ –∑–∞–ø–∏—Å–∏",
                "–°–æ–∑–¥–∞—Ç—å –∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –∞—É–¥–∏–æ"
            ],
            'pdf': [
                "–ò–∑–≤–ª–µ—á—å –æ—Å–Ω–æ–≤–Ω—ã–µ –∏–¥–µ–∏ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞",
                "–°–æ–∑–¥–∞—Ç—å –∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ",
                "–ù–∞–π—Ç–∏ –∫–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã –∏ –≤—ã–≤–æ–¥—ã",
                "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–æ–∫—É–º–µ–Ω—Ç–∞"
            ],
            'document': [
                "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –≥—Ä–∞–º–º–∞—Ç–∏–∫—É –∏ —Å—Ç–∏–ª—å",
                "–£–ª—É—á—à–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–µ–∫—Å—Ç–∞",
                "–°–æ–∫—Ä–∞—Ç–∏—Ç—å –∏–ª–∏ —Ä–∞—Å—à–∏—Ä–∏—Ç—å —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ",
                "–ü–µ—Ä–µ—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç"
            ],
            'spreadsheet': [
                "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ —Ç–∞–±–ª–∏—Ü–µ",
                "–ù–∞–π—Ç–∏ –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏ –∏ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏",
                "–°–æ–∑–¥–∞—Ç—å –≤—ã–≤–æ–¥—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–∞–Ω–Ω—ã—Ö",
                "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞—Å—á–µ—Ç—ã –∏ —Ñ–æ—Ä–º—É–ª—ã"
            ]
        }

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Ñ–∞–π–ª–∞
        file_category = 'document'
        if 'image' in file_type:
            file_category = 'image'
        elif 'pdf' in file_type:
            file_category = 'pdf'
        elif 'audio' in file_type:
            file_category = 'audio'
        elif 'spreadsheet' in file_type or 'excel' in file_type:
            file_category = 'spreadsheet'

        file_suggestions = suggestions.get(file_category, suggestions['document'])
        suggestion_text = "\n".join([f"‚Ä¢ {s}" for s in file_suggestions])

        return (
            f"üîé –§–∞–π–ª '{file_name}' —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω –∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω! "
            f"–í–æ—Ç —á—Ç–æ —è –º–æ–≥—É —Å –Ω–∏–º —Å–¥–µ–ª–∞—Ç—å:\n\n{suggestion_text}"
        )

    def get_supported_file_formats(self) -> dict:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ —Ñ–∞–π–ª–æ–≤

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ñ–æ—Ä–º–∞—Ç–∞–º–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        """
        return {
            'images': self.image_processor.get_supported_formats(),
            'audio': self.audio_processor.get_supported_formats(),
            'documents': self.document_processor.get_supported_formats()
        }

    def get_available_tools(self) -> list:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤

        Returns:
            –°–ø–∏—Å–æ–∫ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
        """
        return [
            {
                'type': tool_type,
                **TOOL_METADATA[tool_type]
            }
            for tool_type in TOOL_METADATA.keys()
        ]

    def set_model(self, model_name: str):
        """
        –ò–∑–º–µ–Ω–µ–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º–æ–π –º–æ–¥–µ–ª–∏

        Args:
            model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        """
        old_model = self.model
        self.model = model_name
        self.response_handler.model = model_name

        logger.info(f"Model changed: {old_model} -> {model_name}")

    def get_current_model(self) -> str:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–π –º–æ–¥–µ–ª–∏

        Returns:
            –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        """
        return self.model

    def get_generation_params(self) -> dict:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏

        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        """
        return self.response_handler.get_generation_params()

    def set_generation_params(
            self,
            temperature: Optional[float] = None,
            presence_penalty: Optional[float] = None,
            frequency_penalty: Optional[float] = None
    ):
        """
        –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏

        Args:
            temperature: –¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ (0-2)
            presence_penalty: –®—Ç—Ä–∞—Ñ –∑–∞ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–∏–µ (-2 –¥–æ 2)
            frequency_penalty: –®—Ç—Ä–∞—Ñ –∑–∞ —á–∞—Å—Ç–æ—Ç—É (-2 –¥–æ 2)
        """
        self.response_handler.set_generation_params(
            temperature=temperature,
            presence_penalty=presence_penalty,
            frequency_penalty=frequency_penalty
        )

    def validate_file(
            self,
            file_path: str,
            file_type: str
    ) -> tuple[bool, Optional[str]]:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è —Ñ–∞–π–ª–∞ –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π

        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
            file_type: MIME —Ç–∏–ø —Ñ–∞–π–ª–∞

        Returns:
            Tuple (is_valid, error_message)
        """
        try:
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞ –∏ –≤–∞–ª–∏–¥–∏—Ä—É–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–º
            if 'image' in file_type:
                if not self.image_processor.validate_image(file_path):
                    return False, "–§–∞–π–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ–≤—Ä–µ–∂–¥–µ–Ω –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"

            elif 'audio' in file_type:
                return self.audio_processor.validate_audio_file(file_path)

            else:
                return self.document_processor.validate_document(file_path)

            return True, None

        except Exception as e:
            logger.error(f"File validation error: {e}")
            return False, str(e)

    async def get_chat_title(
            self,
            chat_id: str,
            prompt: str = "",
            tool_type: str = "default",
    ) -> str:
        """
        üí∞ –ë–Æ–î–ñ–ï–¢–ù–ê–Ø –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –Ω–∞–∑–≤–∞–Ω–∏—è —á–∞—Ç–∞ —Å –ø–æ–º–æ—â—å—é GPT-4o-mini

        –°—Ç–æ–∏–º–æ—Å—Ç—å: ~$0.00015 –∑–∞ –∑–∞–ø—Ä–æ—Å (–≤ 15 —Ä–∞–∑ –¥–µ—à–µ–≤–ª–µ GPT-4o)

        Args:
            chat_id: ID —á–∞—Ç–∞
            prompt: –¢–µ–∫—Å—Ç –ø–µ—Ä–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            tool_type: –¢–∏–ø –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "pdf", "excel", "default")

        Returns:
            –ö–æ—Ä–æ—Ç–∫–æ–µ –∏ –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —á–∞—Ç–∞
        """
        try:
            if not prompt.strip():
                return f"–ß–∞—Ç {tool_type}"

            logger.info(f"Generating chat title for chat {chat_id} (tool: {tool_type})")

            system_prompt = (
                "–°–æ–∑–¥–∞–π –∫–æ—Ä–æ—Ç–∫–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —á–∞—Ç–∞ (–º–∞–∫—Å 5 —Å–ª–æ–≤) –Ω–∞ —Ä—É—Å—Å–∫–æ–º. "
                "–û—Ç–≤–µ—Ç: —Ç–æ–ª—å–∫–æ –Ω–∞–∑–≤–∞–Ω–∏–µ, –±–µ–∑ –∫–∞–≤—ã—á–µ–∫ –∏ —Ç–æ—á–µ–∫."
            )

            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –≤—Ö–æ–¥–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏
            user_prompt = f"–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç: {tool_type}\n–ó–∞–ø—Ä–æ—Å: {prompt[:200]}"

            response = await self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                max_tokens=30,
                temperature=0.7,
            )

            title = response.choices[0].message.content.strip()

            # –û—á–∏—Å—Ç–∫–∞ –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤
            title = title.strip('"').strip("'").strip('.')

            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –Ω–∞ –≤—Å—è–∫–∏–π —Å–ª—É—á–∞–π
            if len(title) > 50:
                title = title[:47] + "..."

            logger.info(f"‚úÖ Chat title generated: '{title}'")
            return title

        except Exception as e:
            logger.warning(f"LLM title generation failed for chat {chat_id}: {e}")

            if prompt.strip():
                words = prompt.strip().split()[:4]
                fallback_title = " ".join(words)
                if len(fallback_title) > 50:
                    fallback_title = fallback_title[:47] + "..."
            else:
                fallback_title = f"{tool_type.capitalize()} —á–∞—Ç"

            logger.info(f"Using fallback title: '{fallback_title}'")
            return fallback_title


# ==================== –ì–õ–û–ë–ê–õ–¨–ù–´–ô –≠–ö–ó–ï–ú–ü–õ–Ø–† –°–ï–†–í–ò–°–ê ====================

_ai_service_instance = None


def get_ai_service() -> AIService:
    """
    –ü–æ–ª—É—á–∏—Ç—å –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä AI —Å–µ—Ä–≤–∏—Å–∞ (Singleton)

    Returns:
        –≠–∫–∑–µ–º–ø–ª—è—Ä AIService
    """
    global _ai_service_instance

    if _ai_service_instance is None:
        try:
            _ai_service_instance = AIService()
            logger.info("AIService instance created successfully")
        except ValueError as e:
            logger.error(f"Failed to initialize AI service: {e}")
            _ai_service_instance = None

    return _ai_service_instance


def reset_ai_service():
    """
    –°–±—Ä–æ—Å –≥–ª–æ–±–∞–ª—å–Ω–æ–≥–æ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ (–¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è)
    """
    global _ai_service_instance
    _ai_service_instance = None
    logger.info("AIService instance reset")


# ==================== –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò ====================

async def quick_ask(
        message: str,
        tool_type: str = "default",
        chat_history: List[Dict[str, Any]] = None
) -> str:
    """
    –ë—ã—Å—Ç—Ä—ã–π —Å–ø–æ—Å–æ–± –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç AI

    Args:
        message: –°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        tool_type: –¢–∏–ø –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
        chat_history: –ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞

    Returns:
        –û—Ç–≤–µ—Ç –æ—Ç AI
    """
    service = get_ai_service()
    if not service:
        return "AI —Å–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"

    context = {'tool_type': tool_type}
    return await service.get_response(message, context, chat_history or [])


async def quick_analyze_file(
        file_path: str,
        file_type: str,
        prompt: str = ""
) -> str:
    """
    –ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞

    Args:
        file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
        file_type: MIME —Ç–∏–ø
        prompt: –ü—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
    """
    service = get_ai_service()
    if not service:
        return "AI —Å–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞ –∏ –≤—ã–∑—ã–≤–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥
    if 'image' in file_type:
        return await service.analyze_image(file_path, prompt)
    else:
        return await service.analyze_document(file_path, file_type, prompt)
