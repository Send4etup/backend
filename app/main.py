from fastapi import FastAPI, HTTPException, Depends, status, File, UploadFile, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from fastapi.staticfiles import StaticFiles
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import Optional, List, Dict, Any
import uuid
import asyncio
import random
import os
import json
import shutil
from pathlib import Path
from datetime import datetime, timedelta
import logging
from dotenv import load_dotenv
import aiofiles
import magic  # –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞
from PIL import Image
import hashlib
import mimetypes

from sqlalchemy.orm import Session

from app.database import get_db
from app.models import Chat, Message
from app.services.ai_service import get_ai_service, AIService
from app.services.cleanup_service import get_cleanup_service

load_dotenv()
AIService()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="School Assistant API", version="1.0.0")

# CORS –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # –í –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ —É–∫–∞–∑–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–æ–º–µ–Ω—ã
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Ñ–∞–π–ª–æ–≤
UPLOAD_DIR = Path("../uploads")
UPLOAD_DIR.mkdir(exist_ok=True)

# –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ç–∏–ø—ã —Ñ–∞–π–ª–æ–≤
SUPPORTED_IMAGE_TYPES = {
    'image/jpeg', 'image/jpg', 'image/png', 'image/gif', 'image/webp', 'image/bmp'
}
SUPPORTED_DOCUMENT_TYPES = {
    'application/pdf', 'application/msword',
    'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
    'text/plain', 'application/rtf', 'text/csv',
    'application/vnd.ms-excel',
    'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
}
SUPPORTED_AUDIO_TYPES = {
   'audio/mpeg', 'audio/mp3', 'audio/wav', 'audio/wave',
   'audio/x-wav', 'audio/m4a', 'audio/mp4', 'audio/aac',
   'audio/webm', 'audio/ogg', 'audio/vorbis', 'audio/flac',
   'audio/x-flac', 'audio/3gpp', 'audio/amr', 'audio/opus'
}

MAX_FILE_SIZE = 50 * 1024 * 1024  # 50 MB
MAX_FILES_PER_MESSAGE = 10

# –ú–æ–Ω—Ç–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∞–π–ª—ã
app.mount("/uploads", StaticFiles(directory="uploads"), name="uploads")

# –°—Ö–µ–º–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
security = HTTPBearer(auto_error=False)

# –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ
chat_storage = {}
user_storage = {}
file_storage = {}

# –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
DEFAULT_USER = {
    "id": 1,
    "telegram_id": 123456789,
    "name": "Test User",
    "current_points": 0,
    "total_points": 0,
    "level": 1,
    "created_at": datetime.now().isoformat()
}
user_storage[1] = DEFAULT_USER


# Pydantic –º–æ–¥–µ–ª–∏
class TelegramAuthRequest(BaseModel):
    telegram_id: Optional[int] = None
    first_name: Optional[str] = None
    last_name: Optional[str] = None
    username: Optional[str] = None
    initData: Optional[str] = None
    user: Optional[Dict[str, Any]] = None


class SendMessageRequest(BaseModel):
    message: str
    tool_type: Optional[str] = None
    chat_id: Optional[str] = None


class AIResponseRequest(BaseModel):
    message: str
    context: Optional[Dict[str, Any]] = {}


class CreateChatRequest(BaseModel):
    title: Optional[str] = "–ù–æ–≤—ã–π —á–∞—Ç"


class CreateToolChatRequest(BaseModel):
    tool_type: str
    tool_title: str
    description: Optional[str] = None


class UserProfileUpdate(BaseModel):
    name: Optional[str] = None
    school_name: Optional[str] = None
    class_name: Optional[str] = None


class FileInfo(BaseModel):
    file_id: str
    original_name: str
    file_path: str
    file_url: str
    file_type: str
    file_size: int
    created_at: str


# –ú–æ–¥–µ–ª–∏ –æ—Ç–≤–µ—Ç–æ–≤
class AuthResponse(BaseModel):
    token: str
    user: Dict[str, Any]


class MessageResponse(BaseModel):
    message_id: str
    chat_id: str
    status: str
    timestamp: str
    files: Optional[List[FileInfo]] = []


class AIResponse(BaseModel):
    message: str
    response_id: str
    timestamp: str


class FileUploadResponse(BaseModel):
    file_id: str
    file_info: FileInfo
    status: str


# –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å —Ñ–∞–π–ª–∞–º–∏
def get_file_hash(file_content: bytes) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ö–µ—à–∞ —Ñ–∞–π–ª–∞"""
    return hashlib.md5(file_content).hexdigest()


def get_safe_filename(filename: str) -> str:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞"""
    # –£–¥–∞–ª—è–µ–º –æ–ø–∞—Å–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
    safe_chars = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789.-_"
    safe_name = "".join(c for c in filename if c in safe_chars)
    return safe_name[:100] if safe_name else "unnamed_file"


def is_supported_file_type(file_type: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ–≥–æ —Ç–∏–ø–∞ —Ñ–∞–π–ª–∞"""
    return file_type in SUPPORTED_IMAGE_TYPES or file_type in SUPPORTED_DOCUMENT_TYPES or file_type in SUPPORTED_AUDIO_TYPES

def is_image_file(file_type: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º"""
    return file_type in SUPPORTED_IMAGE_TYPES

def is_audio_file(file_type: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä–∫–∞, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –∞—É–¥–∏–æ"""
    return file_type in SUPPORTED_AUDIO_TYPES

async def save_uploaded_file(file: UploadFile, user_id: int) -> FileInfo:
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""
    # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
    content = await file.read()
    await file.seek(0)  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —É–∫–∞–∑–∞—Ç–µ–ª—å –≤ –Ω–∞—á–∞–ª–æ

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä
    if len(content) > MAX_FILE_SIZE:
        raise HTTPException(
            status_code=413,
            detail=f"–§–∞–π–ª —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–π. –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä: {MAX_FILE_SIZE // (1024 * 1024)} MB"
        )

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ñ–∞–π–ª–∞
    file_type = file.content_type
    if not file_type:
        file_type = mimetypes.guess_type(file.filename)[0] or 'application/octet-stream'

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø
    if not is_supported_file_type(file_type):
        raise HTTPException(
            status_code=400,
            detail=f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ç–∏–ø —Ñ–∞–π–ª–∞: {file_type}"
        )

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
    file_hash = get_file_hash(content)
    file_extension = Path(file.filename).suffix.lower() if file.filename else ""
    safe_filename = get_safe_filename(file.filename or "file")

    file_id = str(uuid.uuid4())
    unique_filename = f"{file_id}_{file_hash[:8]}{file_extension}"

    # –°–æ–∑–¥–∞–µ–º –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    user_dir = UPLOAD_DIR / str(user_id)
    user_dir.mkdir(exist_ok=True)

    file_path = user_dir / unique_filename

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª
    async with aiofiles.open(file_path, 'wb') as f:
        await f.write(content)

    # –ï—Å–ª–∏ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, —Å–æ–∑–¥–∞–µ–º –ø—Ä–µ–≤—å—é (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    if is_image_file(file_type):
        try:
            await create_image_thumbnail(file_path)
        except Exception as e:
            logger.warning(f"Failed to create thumbnail for {file_path}: {e}")

    # –°–æ–∑–¥–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ
    file_info = FileInfo(
        file_id=file_id,
        original_name=file.filename or "unnamed",
        file_path=str(file_path),
        file_url=f"/uploads/{user_id}/{unique_filename}",
        file_type=file_type,
        file_size=len(content),
        created_at=datetime.now().isoformat()
    )

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ storage
    file_storage[file_id] = {
        **file_info.dict(),
        "user_id": user_id,
        "hash": file_hash
    }

    logger.info(f"File saved: {file_id} ({file.filename}) by user {user_id}")

    return file_info


async def create_image_thumbnail(image_path: Path, max_size: int = 300):
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–≤—å—é –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
    try:
        thumbnail_path = image_path.parent / f"thumb_{image_path.name}"

        with Image.open(image_path) as img:
            img.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
            img.save(thumbnail_path, optimize=True, quality=85)

        logger.info(f"Thumbnail created: {thumbnail_path}")
    except Exception as e:
        logger.error(f"Error creating thumbnail for {image_path}: {e}")


def analyze_file_for_ai(file_info: FileInfo) -> str:
    """–ê–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞ –¥–ª—è –ø–µ—Ä–µ–¥–∞—á–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –≤ AI"""
    context = f"–§–∞–π–ª: {file_info.original_name} ({file_info.file_type}), —Ä–∞–∑–º–µ—Ä: {file_info.file_size // 1024} KB"

    if is_image_file(file_info.file_type):
        context += " [–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ]"
    elif is_audio_file(file_info.file_type):
        context += " [–ê—É–¥–∏–æ—Ñ–∞–π–ª]"
    elif "pdf" in file_info.file_type:
        context += " [PDF –¥–æ–∫—É–º–µ–Ω—Ç]"
    elif "word" in file_info.file_type or "document" in file_info.file_type:
        context += " [–¢–µ–∫—Å—Ç–æ–≤—ã–π –¥–æ–∫—É–º–µ–Ω—Ç]"
    elif "excel" in file_info.file_type or "spreadsheet" in file_info.file_type:
        context += " [–≠–ª–µ–∫—Ç—Ä–æ–Ω–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞]"

    return context


# –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
def generate_mock_token(telegram_id: int) -> str:
    return f"mock_token_{telegram_id}_{int(datetime.now().timestamp())}"


def get_current_user(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–±–µ–∑ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ç–æ–∫–µ–Ω–∞)"""
    return DEFAULT_USER


async def get_gpt_response(message: str, context: Dict[str, Any] = {}) -> str:
    """–ü–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç GPT –∏–ª–∏ fallback"""
    ai_service = get_ai_service()

    if ai_service is None:
        print("AI —Å–µ—Ä–≤–∏—Å –Ω–µ –∑–∞–ø—É—Å—Ç–∏–ª—Å—è!")
        return await simulate_ai_response(message, context)

    try:
        # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        chat_id = context.get('chat_id')
        chat_history = []

        if chat_id and chat_id in chat_storage:
            chat_history = chat_storage[chat_id]["messages"]

        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª–æ–≤ –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
        files_data = []
        if chat_id and chat_id in chat_storage:
            messages = chat_storage[chat_id]["messages"]
            if messages:
                last_message = messages[-1]
                if last_message.get("files") and last_message.get("type") == "user":
                    files_data = last_message["files"]
                    logger.info(f"Found {len(files_data)} files in last message for AI processing")

        # –í—ã–∑—ã–≤–∞–µ–º GPT —Å —Ñ–∞–π–ª–∞–º–∏ (—Ñ–∞–π–ª—ã –±—É–¥—É—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —É–¥–∞–ª–µ–Ω—ã –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏)
        response = await ai_service.get_response(
            message,
            context,
            chat_history,
            files_data
        )

        # –£–¥–∞–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–∞—Ö –∏–∑ storage –ø–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        if files_data:
            for file_data in files_data:
                file_id = file_data.get('file_id')
                if file_id and file_id in file_storage:
                    del file_storage[file_id]
                    logger.info(f"File {file_id} removed from storage after processing")

        return response

    except Exception as e:
        logger.error(f"GPT error, falling back to static response: {e}")

        # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ —Ç–æ–∂–µ –æ—á–∏—â–∞–µ–º —Ñ–∞–π–ª—ã
        if context.get('chat_id') and context['chat_id'] in chat_storage:
            messages = chat_storage[context['chat_id']]["messages"]
            if messages:
                last_message = messages[-1]
                if last_message.get("files"):
                    for file_data in last_message["files"]:
                        file_id = file_data.get('file_id')
                        file_path = file_data.get('file_path')

                        # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª —Å –¥–∏—Å–∫–∞
                        if file_path and os.path.exists(file_path):
                            try:
                                os.remove(file_path)
                                logger.info(f"Cleaned up file after error: {file_path}")
                            except Exception as cleanup_error:
                                logger.warning(f"Failed to cleanup file {file_path}: {cleanup_error}")

                        # –£–¥–∞–ª—è–µ–º –∏–∑ storage
                        if file_id and file_id in file_storage:
                            del file_storage[file_id]

        return await simulate_ai_response(message, context)


async def simulate_ai_response(message: str, context: Dict[str, Any] = {}) -> str:
    """–°—Ç–∞—Ç–∏—á–Ω–∞—è —Å–∏–º—É–ª—è—Ü–∏—è –ò–ò (fallback)"""
    await asyncio.sleep(random.uniform(0.5, 1.0))

    tool_type = context.get('tool_type')
    files_context = context.get('files_context', '')

    file_info = ""
    if files_context:
        file_info = f" –í–∏–∂—É –ø—Ä–∏–∫—Ä–µ–ø–ª–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã: {files_context}."

    if tool_type == 'create_image':
        return f"üé® (–†–µ–∂–∏–º fallback) –ü–æ–Ω—è–ª! –•–æ—Ç–∏—Ç–µ —Å–æ–∑–¥–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: '{message}'.{file_info} –û–ø–∏—à–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω–µ–µ —Å—Ç–∏–ª—å –∏ –¥–µ—Ç–∞–ª–∏!"
    elif tool_type == 'coding':
        return f"üíª (–†–µ–∂–∏–º fallback) –û—Ç–ª–∏—á–Ω–∞—è –∑–∞–¥–∞—á–∞ –ø–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—é! '{message}'{file_info} - –¥–∞–≤–∞–π—Ç–µ —Ä–∞–∑–±–µ—Ä–µ–º –ø–æ—à–∞–≥–æ–≤–æ."
    elif tool_type == 'brainstorm':
        return f"üí° (–†–µ–∂–∏–º fallback) –°—É–ø–µ—Ä —Ç–µ–º–∞ –¥–ª—è –º–æ–∑–≥–æ–≤–æ–≥–æ —à—Ç—É—Ä–º–∞: '{message}'!{file_info} –í–æ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π –¥–ª—è —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–π..."
    elif tool_type == 'excuse':
        return f"üòÖ (–†–µ–∂–∏–º fallback) –ù—É–∂–Ω–∞ –æ—Ç–º–∞–∑–∫–∞ –¥–ª—è '{message}'?{file_info} –ü—Ä–∏–¥—É–º—ã–≤–∞—é –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ!"
    else:
        return f"ü§ñ (–†–µ–∂–∏–º fallback) –ò–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π –≤–æ–ø—Ä–æ—Å! –ü–æ —Ç–µ–º–µ '{message}'{file_info} –º–æ–≥—É –ø—Ä–µ–¥–ª–æ–∂–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –∏–¥–µ–π..."


# –ê–í–¢–û–†–ò–ó–ê–¶–ò–Ø (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è)
@app.post("/api/auth/telegram", response_model=AuthResponse)
async def simple_auth():
    try:
        token = "simple_token_123"
        logger.info(f"User authenticated: {DEFAULT_USER['id']}")
        return AuthResponse(token=token, user=DEFAULT_USER)
    except Exception as e:
        logger.error(f"Auth error: {e}")
        raise HTTPException(status_code=400, detail="Authentication failed")


# –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–¨
@app.get("/api/user/profile")
async def get_user_profile(user=Depends(get_current_user)):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    return user


@app.patch("/api/user/profile")
async def update_user_profile(
        profile_data: UserProfileUpdate,
        user=Depends(get_current_user)
):
    """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ—Ñ–∏–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    user_id = user["id"]

    if profile_data.name:
        user["name"] = profile_data.name
    if profile_data.school_name:
        user["school_name"] = profile_data.school_name
    if profile_data.class_name:
        user["class_name"] = profile_data.class_name

    user["updated_at"] = datetime.now().isoformat()
    user_storage[user_id] = user

    return user


# –§–ê–ô–õ–´
@app.post("/api/files/upload", response_model=FileUploadResponse)
async def upload_file(
        file: UploadFile = File(...),
        chat_id: Optional[str] = Form(None),
        user=Depends(get_current_user)
):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–¥–∏–Ω–æ—á–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""
    try:
        file_info = await save_uploaded_file(file, user["id"])

        return FileUploadResponse(
            file_id=file_info.file_id,
            file_info=file_info,
            status="uploaded"
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"File upload error: {e}")
        raise HTTPException(status_code=500, detail="Failed to upload file")


@app.get("/api/files/{file_id}", response_model=FileInfo)
async def get_file_info(
        file_id: str,
        user=Depends(get_current_user)
):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ñ–∞–π–ª–µ"""
    if file_id not in file_storage:
        raise HTTPException(status_code=404, detail="File not found")

    file_data = file_storage[file_id]

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞
    if file_data["user_id"] != user["id"]:
        raise HTTPException(status_code=403, detail="Access denied")

    return FileInfo(**file_data)


@app.delete("/api/files/{file_id}")
async def delete_file(
        file_id: str,
        user=Depends(get_current_user)
):
    """–£–¥–∞–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–∞"""
    if file_id not in file_storage:
        raise HTTPException(status_code=404, detail="File not found")

    file_data = file_storage[file_id]

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞
    if file_data["user_id"] != user["id"]:
        raise HTTPException(status_code=403, detail="Access denied")

    # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª —Å –¥–∏—Å–∫–∞
    try:
        file_path = Path(file_data["file_path"])
        if file_path.exists():
            file_path.unlink()

        # –£–¥–∞–ª—è–µ–º –ø—Ä–µ–≤—å—é –µ—Å–ª–∏ –µ—Å—Ç—å
        thumbnail_path = file_path.parent / f"thumb_{file_path.name}"
        if thumbnail_path.exists():
            thumbnail_path.unlink()

        # –£–¥–∞–ª—è–µ–º –∏–∑ storage
        del file_storage[file_id]

        logger.info(f"File deleted: {file_id} by user {user['id']}")

        return {"status": "deleted", "file_id": file_id}

    except Exception as e:
        logger.error(f"Error deleting file {file_id}: {e}")
        raise HTTPException(status_code=500, detail="Failed to delete file")


# –ß–ê–¢ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —Ñ–∞–π–ª–æ–≤
@app.post("/api/chat/send-with-files", response_model=MessageResponse)
async def send_message_with_files(
        message: Optional[str] = Form(None),
        chat_id: Optional[str] = Form(None),
        tool_type: Optional[str] = Form(None),
        files: List[UploadFile] = File(...),
        user=Depends(get_current_user)
):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è —Å —Ñ–∞–π–ª–∞–º–∏"""
    if len(files) > MAX_FILES_PER_MESSAGE:
        raise HTTPException(
            status_code=400,
            detail=f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤: {MAX_FILES_PER_MESSAGE}"
        )

    message_id = str(uuid.uuid4())
    chat_id = chat_id or str(uuid.uuid4())

    # –°–æ–∑–¥–∞–µ–º —á–∞—Ç –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    if chat_id not in chat_storage:
        chat_storage[chat_id] = {
            "chat_id": chat_id,
            "user_id": user["id"],
            "tool_type": tool_type,
            "created_at": datetime.now().isoformat(),
            "messages": []
        }

    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª—ã
    uploaded_files = []
    for file in files:
        try:
            file_info = await save_uploaded_file(file, user["id"])
            uploaded_files.append(file_info)
        except HTTPException as e:
            logger.error(f"Failed to upload file {file.filename}: {e.detail}")
            # –ú–æ–∂–Ω–æ –ª–∏–±–æ –ø—Ä–µ—Ä–≤–∞—Ç—å –∑–∞–≥—Ä—É–∑–∫—É, –ª–∏–±–æ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Å –æ—Å—Ç–∞–ª—å–Ω—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏
            continue

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ —Å —Ñ–∞–π–ª–∞–º–∏
    message_data = {
        "message_id": message_id,
        "chat_id": chat_id,
        "user_id": user["id"],
        "message": message,
        "tool_type": tool_type,
        "type": "user",
        "files": [f.dict() for f in uploaded_files],
        "timestamp": datetime.now().isoformat()
    }

    chat_storage[chat_id]["messages"].append(message_data)

    logger.info(f"Message with {len(uploaded_files)} files sent to chat {chat_id}")

    return MessageResponse(
        message_id=message_id,
        chat_id=chat_id,
        status="sent",
        timestamp=message_data["timestamp"],
        files=uploaded_files
    )


@app.post("/api/chat/send", response_model=MessageResponse)
async def send_message(
        request: SendMessageRequest,
        user=Depends(get_current_user)
):
    """–û—Ç–ø—Ä–∞–≤–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —á–∞—Ç"""
    message_id = str(uuid.uuid4())
    chat_id = request.chat_id or str(uuid.uuid4())

    if chat_id not in chat_storage:
        chat_storage[chat_id] = {
            "chat_id": chat_id,
            "user_id": user["id"],
            "tool_type": request.tool_type,
            "created_at": datetime.now().isoformat(),
            "messages": []
        }

    message_data = {
        "message_id": message_id,
        "chat_id": chat_id,
        "user_id": user["id"],
        "message": request.message,
        "tool_type": request.tool_type,
        "type": "user",
        "files": [],
        "timestamp": datetime.now().isoformat()
    }

    chat_storage[chat_id]["messages"].append(message_data)

    logger.info(f"Message sent to chat {chat_id}: {request.message[:50]}...")

    return MessageResponse(
        message_id=message_id,
        chat_id=chat_id,
        status="sent",
        timestamp=message_data["timestamp"],
        files=[]
    )


@app.post("/api/chat/ai-response", response_model=AIResponse)
async def get_ai_response(
        request: AIResponseRequest,
        user=Depends(get_current_user)
):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –ò–ò —Å —É—á–µ—Ç–æ–º —Ñ–∞–π–ª–æ–≤"""
    try:
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
        files_context = ""
        if request.context.get("has_files"):
            chat_id = request.context.get("chat_id")
            if chat_id and chat_id in chat_storage:
                last_message = chat_storage[chat_id]["messages"][-1]
                if last_message.get("files"):
                    file_descriptions = []
                    for file_data in last_message["files"]:
                        file_info = FileInfo(**file_data)
                        file_descriptions.append(analyze_file_for_ai(file_info))
                    files_context = "; ".join(file_descriptions)

        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ñ–∞–π–ª–æ–≤
        context_with_files = {
            **request.context,
            "files_context": files_context
        }

        ai_message = await get_gpt_response(request.message, context_with_files)

        response_id = str(uuid.uuid4())
        chat_id = request.context.get("chat_id")
        tool_type = request.context.get("tool_type")

        if chat_id and chat_id in chat_storage:
            ai_response_data = {
                "message_id": response_id,
                "chat_id": chat_id,
                "user_id": user["id"],
                "message": ai_message,
                "tool_type": tool_type,
                "type": "assistant",
                "files": [],
                "timestamp": datetime.now().isoformat()
            }
            chat_storage[chat_id]["messages"].append(ai_response_data)

        logger.info(f"AI response generated for user {user['id']}, tool_type: {tool_type}")

        return AIResponse(
            message=ai_message,
            response_id=response_id,
            timestamp=datetime.now().isoformat()
        )

    except Exception as e:
        logger.error(f"AI response error: {e}")
        raise HTTPException(status_code=500, detail="Failed to generate AI response")


@app.post("/api/chat/ai-response-stream")
async def get_ai_response_stream(
        request: AIResponseRequest,
        user=Depends(get_current_user)
):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Ç–æ–∫–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –ò–ò —Å —É—á–µ—Ç–æ–º —Ñ–∞–π–ª–æ–≤"""

    async def generate_response():
        try:
            logger.info(f"Stream request received: {request.message[:50]}...")

            ai_service = get_ai_service()
            if not ai_service:
                logger.error("AI service is not available")
                yield f"data: {json.dumps({'type': 'error', 'message': 'AI service unavailable'})}\n\n"
                return

            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å
            files_context = ""
            if request.context.get("has_files"):
                logger.info("Processing files context...")
                chat_id = request.context.get("chat_id")
                if chat_id and chat_id in chat_storage:
                    last_message = chat_storage[chat_id]["messages"][-1]
                    if last_message.get("files"):
                        file_descriptions = []
                        for file_data in last_message["files"]:
                            file_info = FileInfo(**file_data)
                            file_descriptions.append(analyze_file_for_ai(file_info))
                        files_context = "; ".join(file_descriptions)
                        logger.info(f"Files context prepared: {len(file_descriptions)} files")

            # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ñ–∞–π–ª–æ–≤
            context_with_files = {
                **request.context,
                "files_context": files_context
            }

            # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            chat_id = request.context.get("chat_id")
            chat_history = []
            if chat_id and chat_id in chat_storage:
                chat_history = chat_storage[chat_id]["messages"]
                logger.info(f"Chat history loaded: {len(chat_history)} messages")

            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª–æ–≤ –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
            files_data = []
            if chat_id and chat_id in chat_storage:
                messages = chat_storage[chat_id]["messages"]
                if messages:
                    last_message = messages[-1]
                    if last_message.get("files") and last_message.get("type") == "user":
                        files_data = last_message["files"]
                        logger.info(f"Files data loaded: {len(files_data)} files")

            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–∞—á–∞–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            yield f"data: {json.dumps({'type': 'start'})}\n\n"
            logger.info("Stream started, yielding chunks...")

            chunk_count = 0
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Ç–æ–∫–æ–≤—ã–π –æ—Ç–≤–µ—Ç
            async for chunk in ai_service.get_response_stream(
                    request.message,
                    context_with_files,
                    chat_history,
                    files_data
            ):
                chunk_count += 1
                logger.debug(f"Yielding chunk {chunk_count}: {chunk[:30]}...")

                # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–∂–¥—ã–π —á–∞–Ω–∫
                chunk_data = {
                    'type': 'chunk',
                    'content': chunk
                }
                yield f"data: {json.dumps(chunk_data)}\n\n"

                # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
                await asyncio.sleep(0.01)

            # –°–∏–≥–Ω–∞–ª –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
            logger.info(f"Stream completed successfully. Total chunks: {chunk_count}")
            yield f"data: {json.dumps({'type': 'end'})}\n\n"

            # –ùE –æ—á–∏—â–∞–µ–º —Ñ–∞–π–ª—ã –∑–¥–µ—Å—å - –ø—É—Å—Ç—å —ç—Ç–æ –¥–µ–ª–∞–µ—Ç –æ–±—ã—á–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å
            # –≠—Ç–æ –º–æ–∂–µ—Ç –≤—ã–∑—ã–≤–∞—Ç—å –ø—Ä–æ–±–ª–µ–º—ã –≤ streaming —Ä–µ–∂–∏–º–µ

        except Exception as e:
            logger.error(f"AI streaming response error: {str(e)}", exc_info=True)
            error_data = {
                'type': 'error',
                'message': f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {str(e)}'
            }
            yield f"data: {json.dumps(error_data)}\n\n"

    return StreamingResponse(
        generate_response(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Headers": "Cache-Control"
        }
    )

@app.get("/api/chat/history")
async def get_chat_history(
        chat_id: Optional[str] = None,
        limit: int = 20,
        user=Depends(get_current_user)
):
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–æ–≤"""
    user_id = user["id"]

    if chat_id:
        if chat_id in chat_storage and chat_storage[chat_id]["user_id"] == user_id:
            chat = chat_storage[chat_id]
            return chat["messages"][-limit:] if chat["messages"] else []
        else:
            return []
    else:
        user_chats = []
        for chat_id, chat_data in chat_storage.items():
            if chat_data["user_id"] == user_id:
                last_message = chat_data["messages"][-1] if chat_data["messages"] else None

                chat_info = {
                    "chat_id": chat_id,
                    "title": chat_data.get("title", f"–ß–∞—Ç {chat_id[:8]}..."),
                    "last_message": last_message["message"] if last_message else None,
                    "last_message_time": last_message["timestamp"] if last_message else chat_data["created_at"],
                    "message_count": len(chat_data["messages"]),
                    "has_files": any(msg.get("files") for msg in chat_data["messages"])
                }
                user_chats.append(chat_info)

        user_chats.sort(key=lambda x: x["last_message_time"], reverse=True)
        return user_chats[:limit]


@app.post("/api/chat/create")
async def create_new_chat(
        request: CreateChatRequest,
        user=Depends(get_current_user),
        db: Session = Depends(get_db)
):
    """–°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —á–∞—Ç–∞"""
    chat_id = str(uuid.uuid4())

    chat = Chat(
        chat_id=chat_id,  # UUID —á–∞—Ç–∞
        user_id=user["id"],
        type=request.tool_type,
        title=request.tool_title,
        created_at=datetime.utcnow()
    )

    try:
        db.add(chat)
        db.commit()
        db.refresh(chat)  # –ø–æ–ª—É—á–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (id, timestamps)
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —á–∞—Ç–∞: {e}")

    chat_storage[chat_id] = chat
    logger.info(f"New chat created: {chat_id} by user {user['id']}")

    return {
        "chat_id": chat_id,
        "title": request.title,
        "status": "created"
    }


@app.post("/api/chat/create-tool")
async def create_tool_chat(
        request: CreateToolChatRequest,
        user=Depends(get_current_user),
        db: Session = Depends(get_db)
):
    chat_id = str(uuid.uuid4())

    # –°–æ–∑–¥–∞–µ–º ORM-–º–æ–¥–µ–ª—å —á–∞—Ç–∞
    chat = Chat(
        chat_id=chat_id,                # UUID —á–∞—Ç–∞
        user_id=user["id"],
        type=request.tool_type,
        title=request.tool_title,
        created_at=datetime.now()
    )

    try:
        db.add(chat)
        db.commit()
        db.refresh(chat)  # –ø–æ–ª—É—á–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (id, timestamps)
    except Exception as e:
        db.rollback()
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —á–∞—Ç–∞: {e}")

    # –ï—Å–ª–∏ –µ—Å—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ, —Å–æ–∑–¥–∞–µ–º –ø–µ—Ä–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    if request.description:
        initial_message = Message(
            message_id=int(uuid.uuid4()),
            chat_id=chat.chat_id,
            user_id=user["id"],
            content=request.description,
            role="assistant",
        )
        try:
            db.add(initial_message)
            db.commit()
        except Exception as e:
            db.rollback()
            raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")

    return {
        "chat_id": chat.chat_id,
        "tool_type": chat.type,
        "tool_title": chat.title,
        "status": "created"
    }


# –°–ò–°–¢–ï–ú–ù–´–ï –≠–ù–î–ü–û–ò–ù–¢–´
@app.get("/")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Ä–≤–µ—Ä–∞"""
    ai_service = get_ai_service()
    gpt_status = "available" if ai_service else "unavailable"

    if ai_service:
        try:
            gpt_healthy = await ai_service.health_check()
            gpt_status = "healthy" if gpt_healthy else "error"
        except:
            gpt_status = "error"

    return {
        "status": "ok",
        "message": "School Assistant API is running",
        "version": "1.0.0",
        "timestamp": datetime.now().isoformat(),
        "gpt_status": gpt_status,
        "stats": {
            "users": len(user_storage),
            "chats": len(chat_storage),
            "files": len(file_storage)
        }
    }


@app.get("/api/system/info")
async def get_system_info():
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ"""
    total_messages = sum(len(chat["messages"]) for chat in chat_storage.values())

    # –ü–æ–ª—É—á–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ö—Ä–∞–Ω–∏–ª–∏—â–∞
    cleanup_service = get_cleanup_service()
    storage_stats = cleanup_service.get_storage_stats()

    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø–∞–º —Ñ–∞–π–ª–æ–≤
    file_type_stats = {}
    for file_data in file_storage.values():
        file_type = file_data.get("file_type", "unknown")
        file_type_stats[file_type] = file_type_stats.get(file_type, 0) + 1

    return {
        "api_name": "School Assistant API",
        "version": "2.1.0",
        "status": "running",
        "features": [
            "AI Chat with GPT-4o",
            "Vision Analysis",
            "Document Text Extraction",
            "Auto File Cleanup",
            "OCR Support (Optional)",
            "Specialized Tools"
        ],
        "statistics": {
            "total_users": len(user_storage),
            "total_chats": len(chat_storage),
            "total_messages": total_messages,
            "active_files": len(file_storage),
            "storage_used_mb": storage_stats["total_size_mb"],
            "total_files_on_disk": storage_stats["total_files"],
            "file_types": file_type_stats
        },
        "file_limits": {
            "max_file_size_mb": MAX_FILE_SIZE // (1024 * 1024),
            "max_files_per_message": MAX_FILES_PER_MESSAGE,
            "file_retention_hours": 24,
            "cleanup_interval_hours": 1,
            "supported_image_types": list(SUPPORTED_IMAGE_TYPES),
            "supported_document_types": list(SUPPORTED_DOCUMENT_TYPES),
            "supported_audio_types": list(SUPPORTED_AUDIO_TYPES),
        },
        "ai_status": {
            "service_available": get_ai_service() is not None,
            "model": os.getenv("OPENAI_MODEL", "gpt-4o"),
            "vision_enabled": True,
            "document_processing": True
        },
        "endpoints": {
            "auth": "/api/auth/telegram",
            "profile": "/api/user/profile",
            "file_upload": "/api/files/upload",
            "file_analyze": "/api/files/{file_id}/analyze",
            "chat_send": "/api/chat/send",
            "chat_send_files": "/api/chat/send-with-files",
            "chat_ai": "/api/chat/ai-response",
            "chat_history": "/api/chat/history",
            "system_cleanup": "/api/system/cleanup",
            "storage_stats": "/api/system/storage-stats"
        }
    }


# DEBUG –≠–ù–î–ü–û–ò–ù–¢–´
@app.get("/api/debug/storage")
async def debug_get_storage():
    """DEBUG: –ü—Ä–æ—Å–º–æ—Ç—Ä –≤—Å–µ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞"""
    cleanup_service = get_cleanup_service()
    storage_stats = cleanup_service.get_storage_stats()

    return {
        "users": user_storage,
        "chats": {k: {**v, "messages": len(v["messages"])} for k, v in chat_storage.items()},
        "files": {k: {**v, "file_path": "***"} for k, v in file_storage.items()},
        "storage_stats": storage_stats
    }


@app.delete("/api/debug/clear")
async def debug_clear_storage():
    """DEBUG: –û—á–∏—Å—Ç–∫–∞ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞"""
    cleanup_service = get_cleanup_service()

    # –£–¥–∞–ª—è–µ–º –≤—Å–µ —Ñ–∞–π–ª—ã
    for file_id, file_data in file_storage.items():
        try:
            file_path = Path(file_data["file_path"])
            if file_path.exists():
                file_path.unlink()

            # –£–¥–∞–ª—è–µ–º –ø—Ä–µ–≤—å—é
            thumbnail_path = file_path.parent / f"thumb_{file_path.name}"
            if thumbnail_path.exists():
                thumbnail_path.unlink()
        except Exception as e:
            logger.error(f"Error deleting file during debug cleanup: {e}")

    # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –≤—Å–µ—Ö —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤
    await cleanup_service.cleanup_old_files()

    # –û—á–∏—â–∞–µ–º storage
    chat_storage.clear()
    user_storage.clear()
    file_storage.clear()

    # –ü–µ—Ä–µ—Å–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    user_storage[1] = DEFAULT_USER.copy()

    # –ü–æ–ª—É—á–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    final_stats = cleanup_service.get_storage_stats()

    return {
        "status": "cleared",
        "message": "All data and files cleared",
        "remaining_files": final_stats
    }


@app.get("/api/debug/files")
async def debug_list_files():
    """DEBUG: –°–ø–∏—Å–æ–∫ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤"""
    cleanup_service = get_cleanup_service()
    storage_stats = cleanup_service.get_storage_stats()

    files_info = []
    for file_id, file_data in file_storage.items():
        file_path = Path(file_data["file_path"])
        files_info.append({
            "file_id": file_id,
            "original_name": file_data["original_name"],
            "file_type": file_data["file_type"],
            "file_size": file_data["file_size"],
            "exists_on_disk": file_path.exists(),
            "created_at": file_data["created_at"],
            "age_hours": (datetime.now() - datetime.fromisoformat(file_data["created_at"])).total_seconds() / 3600
        })

    return {
        "total_files_in_storage": len(files_info),
        "total_files_on_disk": storage_stats["total_files"],
        "storage_size_mb": storage_stats["total_size_mb"],
        "files": files_info,
        "cleanup_info": {
            "max_age_hours": 24,
            "cleanup_interval_hours": 1,
            "next_cleanup": "Automatic every hour"
        }
    }


@app.post("/api/debug/emergency-cleanup")
async def debug_emergency_cleanup(max_size_mb: float = 100):
    """DEBUG: –≠–∫—Å—Ç—Ä–µ–Ω–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ –ª–∏–º–∏—Ç–æ–≤"""
    cleanup_service = get_cleanup_service()

    stats_before = cleanup_service.get_storage_stats()
    await cleanup_service.emergency_cleanup(max_size_mb)
    stats_after = cleanup_service.get_storage_stats()

    return {
        "status": "emergency_cleanup_completed",
        "before": stats_before,
        "after": stats_after,
        "freed_mb": stats_before["total_size_mb"] - stats_after["total_size_mb"],
        "timestamp": datetime.now().isoformat()
    }


if __name__ == "__main__":
    import uvicorn

    print("üöÄ Starting School Assistant API with File Support...")
    print("üìç Server: http://127.0.0.1:3213")
    print("üìö API Docs: http://127.0.0.1:3213/docs")
    print("üìÅ File uploads will be stored in: uploads/")
    print("üîó Static files available at: http://127.0.0.1:3213/uploads/")

    uvicorn.run(app, host="127.0.0.1", port=3213)